---
title: "Homework-10.11"
author: 'By 19087'
date: "2019/10/16"
output: html_document
---  

## Question 5.1  

Compute a Monte Carlo estimate of  $$ \displaystyle \int ^{\pi/3}_{0}{sint dt}$$  
and compare your estimate with the exact value of the integral.  

---  

## Answer  

We use the simple algorithm.  
$$g(t)=\frac{\pi}{3}sint,T \sim  U(0,\frac{pi}{3})$$  
Then we generate $T_1,T_2,...,T_m$ from T and calculate $\frac{1}{m}\sum_{i=1}^{m}g(T_i).$  

```{r}

m<-1e4
T<-runif(m,min=0,max=pi/3)  
theta.hat<-mean(sin(T)*pi/3)  
print(c(theta.hat,-cos(pi/3)+cos(0)))  
```

The bias is small.  

---  

## Question 5.10  

Use Monte Carlo integration with antithetic variables to estimate  
$$\displaystyle \int ^{1}_{0} {\frac{e^{-x}}{1+x^2}dx}$$  
and find the approximate reduction in variance as a percentage of the variance without variance reduction.  

---  

## Answer  

```{r}
m<-1e4
MC1<-1:1000
MC2<-1:1000
set.seed(123)
for(i in 1:1000){

u<-runif(m/2)
v<-runif(m/2)
x1<-c(u,1-u)       ##sample with antithetic reduction
x2<-c(u,v) ##sample without variance reduction
MC1[i]<-mean(exp(-x1)/(1+x1^2))
MC2[i]<-mean(exp(-x2)/(1+x2^2))
}
print(c(mean(MC1),mean(MC2),1-var(MC1)/var(MC2)))
```
The estimate with antithetic variables is `r mean(MC1)`.  
The percentage is about `r 1-var(MC1)/var(MC2)` .  

---  

## Question 5.15  


Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.  

---  

## Answer  
for interval (0,1)
$$F(x)=\frac{1-e^{-x}}{1-e^{-1}}$$
$$F^{-1}(x)=-log(1-(1-e^{-1})x)$$

So we divide the interval (0,1) into five subintervals:$(0,F^{-1}(0.2)),(F^{-1}(0.2),F^{-1}(0.4)),(F^{-1}(0.4),F^{-1}(0.6)),(F^{-1}(0.6),F^{-1}(0.8)),(F^{-1}(0.8),F^{-1}(1)).$  


for subintervals:

Note $F_0(x)$ as the cdf of x.
So $F_0(x)=5 \cdot \frac{e^{-qi}-e^{-x}}{1-e^{-1}},the \space ith\space subinterval$  
$$F_0^{-1}(x)=-log(e^{-qi}-(1-e^{-1})\frac{x}{5}),the \space ith\space subinterval$$  
for the ith subinterval, qi is the inf of the subinterval.
```{r}
a<-c(0.2,0.4,0.6,0.8)
p<--log(1-(1-exp(-1))*a)
u1<-runif(2000)
u2<-runif(2000)
u3<-runif(2000)
u4<-runif(2000)
u5<-runif(2000)
x1<--log(1-(1-exp(-1))*u1/5)     ## xi: the random sample in ith subinterval
x2<--log(exp(-p[1])-(1-exp(-1))*u2/5)
x3<--log(exp(-p[2])-(1-exp(-1))*u3/5)
x4<--log(exp(-p[3])-(1-exp(-1))*u4/5)
x5<--log(exp(-p[4])-(1-exp(-1))*u5/5)
y1<-exp(-x1)/(1+x1^2)/(5*exp(-x1)/(1-exp(-1)))
y2<-exp(-x2)/(1+x2^2)/(5*exp(-x2)/(1-exp(-1)))
y3<-exp(-x3)/(1+x3^2)/(5*exp(-x3)/(1-exp(-1)))
y4<-exp(-x4)/(1+x4^2)/(5*exp(-x4)/(1-exp(-1)))
y5<-exp(-x5)/(1+x5^2)/(5*exp(-x5)/(1-exp(-1)))
fg<-y1+y2+y3+y4+y5
mean(fg)
sd(fg)
```  

By calculation, this estimate is more accurate and has smaller standard error.