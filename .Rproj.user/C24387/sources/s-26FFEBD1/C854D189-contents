---
title: "Homework-2019.10.18"
author: 'by 19087'
date: "2019/10/21"
output: html_document
---

## Question 6.5  

  Suppose a 95% symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $\chi^2(2)$ data with sample size n = 20. Compare your t-interval results with the simulation results in Example 6.4. (The t-interval should be more robust to departures from normality than the interval for variance.)  
 
 
---  

## Answer  

```{r}
n<-20
alpha<-0.05
m=1e3
UCL1<-numeric(m)
LCL1<-numeric(m)
judge1<-numeric(m)
UCL2<-numeric(m)
LCL2<-numeric(m)
judge2<-numeric(m)
for(i in 1:m){
x<-rchisq(n,df=2)
UCL1[i]<-mean(x)+qt(1-alpha/2,n-2)*sd(x)/sqrt(n)
LCL1[i]<-mean(x)-qt(1-alpha/2,n-2)*sd(x)/sqrt(n)
UCL2[i]<-(n-1)*var(x)/qchisq(alpha,df=n-1) 
judge1[i]<-(UCL1[i]>2&&LCL1[i]<2)+0  ##t-interval
judge2[i]<-(UCL2[i]>4)+0  ##interval for variance
}  ## for chisq distribution with df=n,the mean of r.v. is n,the var is 2n.X~chisq(2),so mean(X)=2,var(X)=4

```  

The estimate of coverage probability of t-interval is 
```{r} 
mean(judge1)
```

The estimate of coverage probability of interval for variance is 
```{r} 
mean(judge2)
```

It's far greater than the interval for variance,as the question mentioned, 'the t-interval should be more robust to departures from normality than the interval for variance'.  

---  

##Question 6.6  

  Estimate the 0.025, 0.05, 0.95, and 0.975 quantiles of the skewness $\sqrt{b1}$ under normality by a Monte Carlo experiment. Compute the standard error of the estimates from (2.14) using the normal approximation for the density (with exact variance formula). Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt{b1}$ ?? N(0,6/n).  
 
---  

## Answer  

First, we estimate the quantiles.

```{r}
n<-1e3
m<-1e4
sk<-numeric(n)
for(i in 1:n){
  x<-rnorm(m)  ## generate samples from N(0,1)
  xbar<-mean(x)
  m3<-mean((x-xbar)^3)
  m2<-mean((x-xbar)^2)
  sk[i]<-m3/m2^1.5
}
sk<-sort(sk)
xq<-sk[c(floor(0.025*n),floor(0.05*n),ceiling(0.95*n),ceiling(0.975*n))]
print(xq)##the estimated quantiles  
```  

Then we compute the standard error.  

```{r}
q<-c(0.025,0.05,0.95,0.975)
var_xq<-q*(1-q)/(n*dnorm(xq,mean=0,sd=sqrt(6*(n-2)/(n+1)/(n+3)))^2)
sd_xq<-sqrt(var_xq)
print(sd_xq)
```  

Then we compare the estimated quantiles with the quantiles of N(0,6/n).  

```{r}
print(xq)  
print(qnorm(c(0.025,0.05,0.95,0.975),mean=0,sd=sqrt(6/n)))
```  

We find they are not similar, so we take a larger n just for comparison.  

```{r}

n<-1e4
m<-1e4
sk<-numeric(n)
for(i in 1:n){
  x<-rnorm(m)  ## generate samples from N(0,1)
  xbar<-mean(x)
  m3<-mean((x-xbar)^3)
  m2<-mean((x-xbar)^2)
  sk[i]<-m3/m2^1.5
}
sk<-sort(sk)
xq<-sk[c(floor(0.025*n),floor(0.05*n),ceiling(0.95*n),ceiling(0.975*n))]
print(xq)
print(qnorm(c(0.025,0.05,0.95,0.975),mean=0,sd=sqrt(6/n)))
```  

This time we get a much better conclusion. And we see the estimated quantiles don't have a big change,which means the estimate is great.  

And for n=10000,the sds of quantiles are:  

```{r}
q<-c(0.025,0.05,0.95,0.975)
var_xq<-q*(1-q)/(n*dnorm(xq,mean=0,sd=sqrt(6*(n-2)/(n+1)/(n+3)))^2)
sd_xq<-sqrt(var_xq)
print(sd_xq)
```  

It's much smaller than n=1000.
