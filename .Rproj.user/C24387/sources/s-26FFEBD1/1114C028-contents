---
title: "Homework-11.22"
author: "By 19087"
date: "2019/11/28"
output: html_document
---

## Question 8.3  

 The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal.  
 
---  

## Answer  

We'll use the K-S statistic.  

```{r}
R<-999
n1<-20
n2<-30
mu1<-mu2<-0
sigma1<-sigma2<-1
x<-rnorm(n1,mean=mu1,sd=sigma1)
y<-rnorm(n2,mean=mu2,sd=sigma2)

z<-c(x,y)
K<-1:(n1+n2)
D<-numeric(R)
options(warn=-1)
D0<-ks.test(x,y,exact=FALSE)$statistic
for(i in 1:R){
  k<-sample(K,size=n1,replace=FALSE)
  x1<-z[k]
  y1<-z[-k]
  D[i]<-ks.test(x1,y1,exact=FALSE)$statistic
}
p<-mean(c(D0,D)>=D0)
options(warn=0)
print(p)
```  

The approximate ASL `r p` does not support the alternative hypothesis that distributions differ.   

A histogram of the replicates of D is displayed by:  

```{r}
hist(D, main = "", freq = FALSE, breaks = "scott")
points(D0, 0, cex = 1, pch = 16)  

```  

---  

## Question on slides  

Power comparison (distance correlation test versus ball covariance test)  
  
  Model 1: $Y=X/4+e$  
  Model 2: $Y=X/4\times e$  
  $X\sim N(0_2,I_2)$, $e\sim N(0_2,I_2)$, $X$ and $e$ are independent.  
  
---  

## Answer  

```{r}
library(Ball)
library(boot)
library(mvtnorm)
alpha<-0.1
n0<-c(10,20,30,40,50,60,70,80,90,100)
dCov <- function(x, y) {
x <- as.matrix(x)
y <- as.matrix(y)
n <- nrow(x)
m <- nrow(y)
if (n != m || n < 2) stop("Sample sizes must agree")
if (! (all(is.finite(c(x, y)))))
stop("Data contains missing or infinite values")
Akl <- function(x) {
d <- as.matrix(dist(x))
m <- rowMeans(d)
M <- mean(d)
a <- sweep(d, 1, m)
b <- sweep(a, 2, m)
return(b + M)
}
A <- Akl(x)
B <- Akl(y)
dCov <- sqrt(mean(A * B))
dCov
}
pd1<-pd2<-pb1<-pb2<-numeric(100)
pod1<-pod2<-pob1<-pob2<-numeric(10)
ndCov2 <- function(z, ix, dims) {
  #dims contains dimensions of x and y 
  p <- dims[1]
  q <- dims[2]
  d <- p + q
  x <- z[ , 1:p] #leave x as is
  y <- z[ix, -(1:p)] #permute rows of y 
  return(nrow(z) * dCov(x, y)^2)
}
for(i in 1:10){
  for(j in 1:100){
  I2<-matrix(c(1,0,0,1),nrow=2)
  x<-rmvnorm(n0[i],rep(0,2),I2)
  e<-rmvnorm(n0[i],rep(0,2),I2)
  y1<-x/4+e
 
  y2<-x/4*e
  z1<-cbind(x,y1)
  z2<-cbind(x,y2)
  boot.obj1<-boot(data=z1,statistic=ndCov2,R=99,sim="permutation",dims=c(2,2))
  boot.obj2<-boot(data=z2,statistic=ndCov2,R=99,sim="permutation",dims=c(2,2))
  tb1<-c(boot.obj1$t0,boot.obj1$t)
  tb2<-c(boot.obj2$t0,boot.obj2$t)
  pd1[j]<-mean(tb1>=tb1[1])
  pd2[j]<-mean(tb2>=tb2[1])
  pb1[j]<-bcov.test(z1[,1:2],z1[,3:4],R=100,seed=j*12345)$p.value
  pb2[j]<-bcov.test(z2[,1:2],z2[,3:4],R=100,seed=j*23456)$p.value
  }
  pod1[i]<-mean(pd1<alpha)
  pod2[i]<-mean(pd2<alpha)
  pob1[i]<-mean(pb1<alpha)
  pob2[i]<-mean(pb2<alpha)
}
## Model 1
plot(n0,pod1,type="l",xlab='sample size',ylab='power',ylim=c(0,1),main='Model 1')
lines(n0,pob1,type="l")
points(n0,pod1)
points(n0,pob1)
## Model 2
plot(n0,pod2,type="l",xlab='sample size',ylab='power',ylim=c(0,1),main='Model 2')
lines(n0,pob2,type="l")
points(n0,pod2)
points(n0,pob2)
```